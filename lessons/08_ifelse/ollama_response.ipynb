{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066dd655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma3:270m\",\n",
    "    temperature=0,  \n",
    ")\n",
    "response=llm.invoke(\"write a poem about india\")\n",
    "output= response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06feac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace05368",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(output) > 200:\n",
    "    print(\"Long response generated!\")\n",
    "    print(f\"Response length: {len(output)} characters\")\n",
    "    print(\"First 100 characters:\", output[:100])\n",
    "else:\n",
    "    print(\"Short response generated!\")\n",
    "    print(f\"Response length: {len(output)} characters\")\n",
    "    print(\"Full response:\", output)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76641d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dde217",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I'm feeling sad today\"\n",
    "\n",
    "if \"sad\" in user_input.lower() or \"depressed\" in user_input.lower():\n",
    "    prompt = \"Write something uplifting and motivational\"\n",
    "    tone = \"Supportive\"\n",
    "elif \"happy\" in user_input.lower() or \"excited\" in user_input.lower():\n",
    "    prompt = \"Write something fun and energetic\"\n",
    "    tone = \"Enthusiastic\"\n",
    "elif \"angry\" in user_input.lower() or \"frustrated\" in user_input.lower():\n",
    "    prompt = \"Write something calming and peaceful\"\n",
    "    tone = \"Calming\"\n",
    "else:\n",
    "    prompt = \"Write something neutral and informative\"\n",
    "    tone = \"Neutral\"\n",
    "\n",
    "print(f\"Detected tone: {tone}\")\n",
    "llm.temperature = 0.6\n",
    "response = llm.invoke(prompt)\n",
    "output = response.content\n",
    "print(\"AI Response:\", output)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ab0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22be820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b2feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"python programming\"\n",
    "response = llm.invoke(f\"explain {topic}\")\n",
    "output = response.content\n",
    "\n",
    "if len(output) < 50:\n",
    "    print(\"Response too short, asking for more details...\")\n",
    "    new_response = llm.invoke(f\"explain {topic} in more detail with examples\")\n",
    "    final_output = new_response.content\n",
    "    print(\"Extended response:\", final_output)\n",
    "elif len(output) > 500:\n",
    "    print(\"Response too long, showing summary...\")\n",
    "    # Show first 200 characters\n",
    "    summary = output[:200] + \"...\"\n",
    "    print(\"Summary:\", summary)\n",
    "else:\n",
    "    print(\"Response length is perfect!\")\n",
    "    print(\"Response:\", output)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f92861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7047067c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2945ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "response = llm.invoke(\"write a quote about technology\")\n",
    "end_time = time.time()\n",
    "\n",
    "response_time = end_time - start_time\n",
    "output = response.content\n",
    "\n",
    "if response_time < 2:\n",
    "    print(f\"⚡ Fast response! ({response_time:.2f} seconds)\")\n",
    "    status = \"Excellent\"\n",
    "elif response_time < 5:\n",
    "    print(f\"✓ Normal response time ({response_time:.2f} seconds)\")\n",
    "    status = \"Good\"\n",
    "else:\n",
    "    print(f\"⏰ Slow response ({response_time:.2f} seconds)\")\n",
    "    status = \"Consider optimizing\"\n",
    "\n",
    "print(f\"Performance status: {status}\")\n",
    "print(\"Generated haiku:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bdd038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
