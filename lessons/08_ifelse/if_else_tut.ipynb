{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f57cbbff",
   "metadata": {},
   "source": [
    "# Why are If-Else Statements Important in AI?\n",
    "* In generative AI and machine learning, if-else statements help with:\n",
    "\n",
    "* Data preprocessing: Cleaning and filtering data before training\n",
    "* Model logic: Implementing decision trees and rule-based systems\n",
    "* Output processing: Formatting AI responses based on different conditions\n",
    "* Error handling: Managing different scenarios in AI workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee30f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "if condition:\n",
    "    # Code to execute if condition is True\n",
    "   \n",
    "else:\n",
    "   \n",
    "    # Code to execute if condition is False\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675a419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: AI model confidence check\n",
    "confidence_score = 0.85\n",
    "\n",
    "if confidence_score > 0.8:\n",
    "    print(\"High confidence prediction!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4346537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: AI response quality check\n",
    "response_length = 50\n",
    "\n",
    "if response_length > 100:\n",
    "    print(\"Detailed response generated\")\n",
    "else:\n",
    "    print(\"Brief response generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: AI model performance evaluation\n",
    "accuracy = 0.92\n",
    "\n",
    "if accuracy >= 0.95:\n",
    "    print(\"Excellent model performance!\")\n",
    "elif accuracy >= 0.85:\n",
    "    print(\"Good model performance\")\n",
    "elif accuracy >= 0.70:\n",
    "    print(\"Average model performance\")\n",
    "else:\n",
    "    print(\"Model needs improvement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb52ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common comparison operators\n",
    "x = 10\n",
    "y = 5\n",
    "\n",
    "print(x == y)    # Equal to: False\n",
    "print(x != y)    # Not equal to: True\n",
    "print(x > y)     # Greater than: True\n",
    "print(x < y)     # Less than: False\n",
    "print(x >= y)    # Greater than or equal to: True\n",
    "print(x <= y)    # Less than or equal to: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d26a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: AI training data validation\n",
    "data_size = 10000\n",
    "data_quality = 0.9\n",
    "\n",
    "# Using 'and' operator\n",
    "if data_size > 5000 and data_quality > 0.8:\n",
    "    print(\"Ready for training!\")\n",
    "else:\n",
    "    print(\"Need more or better data\")\n",
    "\n",
    "# Using 'or' operator\n",
    "temperature = 0.7\n",
    "max_tokens = 150\n",
    "\n",
    "if temperature > 1.0 or max_tokens > 200:\n",
    "    print(\"High creativity settings\")\n",
    "else:\n",
    "    print(\"Balanced settings\")\n",
    "\n",
    "# Using 'not' operator\n",
    "is_training_complete = False\n",
    "\n",
    "if not is_training_complete:\n",
    "    print(\"Continue training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5945603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: AI model deployment decision\n",
    "model_accuracy = 0.88\n",
    "deployment_cost = 1000\n",
    "budget = 1500\n",
    "\n",
    "if model_accuracy > 0.85:\n",
    "    print(\"Model accuracy is acceptable\")\n",
    "    if deployment_cost <= budget:\n",
    "        print(\"Deploy the model!\")\n",
    "    else:\n",
    "        print(\"Need more budget for deployment\")\n",
    "else:\n",
    "    print(\"Model needs more training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587f8139",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_request = \"Give me a summary\"\n",
    "max_words = 100\n",
    "\n",
    "if \"detailed\" in user_request.lower():\n",
    "    word_limit = max_words * 2\n",
    "    print(f\"Generating detailed response (up to {word_limit} words)\")\n",
    "elif \"brief\" in user_request.lower():\n",
    "    word_limit = max_words // 2\n",
    "    print(f\"Generating brief response (up to {word_limit} words)\")\n",
    "else:\n",
    "    word_limit = max_words\n",
    "    print(f\"Generating standard response (up to {word_limit} words)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58fe827",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type = \"text_generation\"\n",
    "data_size = \"large\"\n",
    "computational_budget = \"medium\"\n",
    "\n",
    "if task_type == \"text_generation\":\n",
    "    if data_size == \"large\" and computational_budget == \"high\":\n",
    "        model = \"GPT-4\"\n",
    "    elif data_size == \"medium\" or computational_budget == \"medium\":\n",
    "        model = \"GPT-3.5\"\n",
    "    else:\n",
    "        model = \"GPT-2\"\n",
    "elif task_type == \"image_generation\":\n",
    "    model = \"DALL-E\"\n",
    "else:\n",
    "    model = \"Custom model needed\"\n",
    "\n",
    "print(f\"Recommended model: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68609f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Cleaning AI training data\n",
    "text_data = \"This is a sample text with 123 numbers!\"\n",
    "\n",
    "if len(text_data) < 10:\n",
    "    print(\"Text too short, skipping...\")\n",
    "elif any(char.isdigit() for char in text_data):\n",
    "    # Remove numbers\n",
    "    clean_text = ''.join(char for char in text_data if not char.isdigit())\n",
    "    print(f\"Cleaned text: {clean_text}\")\n",
    "else:\n",
    "    print(f\"Text is clean: {text_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07466cde",
   "metadata": {},
   "source": [
    "# common mistakes to avoid\n",
    "* Mistake 1: Forgetting the colon (:)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c4b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d3f2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong\n",
    "if condition\n",
    "    print(\"Hello\")\n",
    "\n",
    "# Correct\n",
    "if condition:\n",
    "    print(\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d760692",
   "metadata": {},
   "source": [
    "# Mistake 2: Incorrect indentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8578179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong\n",
    "if condition:\n",
    "print(\"Hello\")\n",
    "\n",
    "# Correct\n",
    "if condition:\n",
    "    print(\"Hello\")  # 4 spaces indentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a504340b",
   "metadata": {},
   "source": [
    "# Mistake 3: Using = instead of =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e3feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong (assignment)\n",
    "if x = 5:\n",
    "    print(\"x is 5\")\n",
    "\n",
    "# Correct (comparison)\n",
    "if x == 5:\n",
    "    print(\"x is 5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
